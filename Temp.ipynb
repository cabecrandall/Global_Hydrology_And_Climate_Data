{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2StspCH7ZZPC",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:33:50.115135Z",
     "start_time": "2024-01-20T03:33:47.095740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-LqBBYCZbFi"
   },
   "outputs": [],
   "source": [
    "!pip install geemap &> install.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2QYj-D2cZc85",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:33:59.315745Z",
     "start_time": "2024-01-20T03:33:56.556080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (0.13.2)\r\n",
      "Requirement already satisfied: fiona>=1.8.19 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from geopandas) (1.9.5)\r\n",
      "Requirement already satisfied: packaging in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from geopandas) (23.2)\r\n",
      "Requirement already satisfied: pandas>=1.1.0 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from geopandas) (1.5.2)\r\n",
      "Requirement already satisfied: pyproj>=3.0.1 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from geopandas) (3.6.1)\r\n",
      "Requirement already satisfied: shapely>=1.7.1 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from geopandas) (2.0.2)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (23.2.0)\r\n",
      "Requirement already satisfied: click~=8.0 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (8.1.7)\r\n",
      "Requirement already satisfied: click-plugins>=1.0 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (1.1.1)\r\n",
      "Requirement already satisfied: cligj>=0.5 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (0.7.2)\r\n",
      "Requirement already satisfied: six in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (1.16.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from fiona>=1.8.19->geopandas) (69.0.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from pandas>=1.1.0->geopandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from pandas>=1.1.0->geopandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from pandas>=1.1.0->geopandas) (1.24.3)\r\n",
      "Requirement already satisfied: certifi in /Users/calebcrandall/miniconda3/envs/idealabs/lib/python3.10/site-packages (from pyproj>=3.0.1->geopandas) (2023.11.17)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gKpNEMG2ZfOB",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:34:11.563145Z",
     "start_time": "2024-01-20T03:34:11.556974Z"
    }
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q9k1cecqZhzx",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:34:17.296330Z",
     "start_time": "2024-01-20T03:34:14.677204Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate(auth_mode='notebook')\n",
    "    ee.Initialize(project='potential-evap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jQ4pV3Oweld_",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:34:21.712622Z",
     "start_time": "2024-01-20T03:34:20.501382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077\n"
     ]
    }
   ],
   "source": [
    "# TEST SHAPES LIST\n",
    "shapefiles_list = []\n",
    "finished_basins = []\n",
    "path = \"GAGES_smooth_shp\"\n",
    "finished_path = \"Temp_TS\"\n",
    "\n",
    "for file in os.listdir(finished_path):\n",
    "  finished_basins.append(file[-12:-4])\n",
    "\n",
    "\n",
    "for file in os.listdir(path):\n",
    "  if file.endswith('.shp'):\n",
    "    file_path = os.path.join(path,file)\n",
    "    basin_no = file_path[-12:-4] #string\n",
    "    if basin_no not in finished_basins:\n",
    "      shapefiles_list.append(file_path)\n",
    "\n",
    "print(len(shapefiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "27kXc6aaa92c",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:34:25.907878Z",
     "start_time": "2024-01-20T03:34:25.891488Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_bits(image, start, end=None, new_name=None):\n",
    "    \"\"\"Function to convert qa bits to binary flag image\n",
    "\n",
    "    args:\n",
    "        image (ee.Image): qa image to extract bit from\n",
    "        start (int): starting bit for flag\n",
    "        end (int | None, optional): ending bit for flag, if None then will only use start bit. default = None\n",
    "        new_name (str | None, optional): output name of resulting image, if None name will be {start}Bits. default = None\n",
    "\n",
    "    returns:\n",
    "        ee.Image: image with extract bits\n",
    "    \"\"\"\n",
    "\n",
    "    newname = new_name if new_name is not None else f\"{start}_bits\"\n",
    "\n",
    "    if (start == end) or (end is None):\n",
    "        # perform a bit shift with bitwiseAnd\n",
    "        return image.select([0], [newname]).bitwiseAnd(1 << start)\n",
    "    else:\n",
    "        # Compute the bits we need to extract.\n",
    "        pattern = 0\n",
    "        for i in range(start, end):\n",
    "            pattern += int(math.pow(2, i))\n",
    "\n",
    "        # Return a single band image of the extracted QA bits, giving the band\n",
    "        # a new name.\n",
    "        return image.select([0], [newname]).bitwiseAnd(pattern).rightShift(start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Mn0Y9BF7bNQi",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:34:27.287129Z",
     "start_time": "2024-01-20T03:34:27.280885Z"
    }
   },
   "outputs": [],
   "source": [
    "bounds = None\n",
    "def region_temp(image): # THESE MAPPED FUNCTIONS ONLY TAKE ONE ARGUEMENT (AN IMAGE)\n",
    "    # reduction function\n",
    "    temp = image.reduceRegion( #zonal statistics\n",
    "        reducer = ee.Reducer.mean(),\n",
    "        geometry = bounds,\n",
    "        # geometry = Map.draw_features[0].geometry(),\n",
    "        scale = 1000 # 1 km\n",
    "    )\n",
    "\n",
    "    # set the result as a metadata property in the image\n",
    "    return image.set(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9LgOfPqJg4V1",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:34:28.109793Z",
     "start_time": "2024-01-20T03:34:28.096837Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_day(image):\n",
    "    qa_band = image.select(\"QC_Day\")\n",
    "\n",
    "    mask = extract_bits(qa_band, start=2, end=3).eq(0)\n",
    "\n",
    "    return image.multiply(0.02).subtract(273.15).updateMask(mask).copyProperties(image,[\"system:time_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "g60gmmpCbRFa",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:34:28.629183Z",
     "start_time": "2024-01-20T03:34:28.618581Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_night(image):\n",
    "    qa_band = image.select(\"QC_Night\")\n",
    "\n",
    "    mask = extract_bits(qa_band, start=2, end=3).eq(0)\n",
    "\n",
    "    return image.multiply(0.02).subtract(273.15).updateMask(mask).copyProperties(image,[\"system:time_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prYWLKQcoOcf",
    "outputId": "245af213-dcc3-4b3b-8b6e-6a82d715de19",
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-20T03:34:29.100725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 . YES \t 06752260\n",
      "1 . YES \t 11087020\n",
      "2 . YES \t 07242350\n",
      "3 . YES \t 05542000\n",
      "4 . YES \t 11266500\n",
      "5 . YES \t 07359002\n",
      "6 . YES \t 02146750\n",
      "7 . YES \t 08068390\n",
      "8 . YES \t 11151300\n",
      "9 . YES \t 07299540\n",
      "10 . YES \t 05446500\n",
      "11 . YES \t 09484580\n",
      "12 . YES \t 06928300\n",
      "13 . YES \t 15518000\n",
      "14 . YES \t 09468500\n",
      "15 . YES \t 10172800\n",
      "16 . YES \t 06316400\n",
      "17 . YES \t 02334430\n",
      "18 . YES \t 02270500\n",
      "19 . YES \t 06430850\n",
      "20 . YES \t 03112000\n",
      "21 . YES \t 02425000\n",
      "22 . YES \t 09239500\n",
      "23 . YES \t 02370500\n",
      "24 . YES \t 09047700\n",
      "25 . YES \t 01115670\n",
      "26 . YES \t 01414000\n",
      "27 . YES \t 14156500\n",
      "28 . YES \t 06898400\n",
      "29 . YES \t 05059600\n",
      "30 . YES \t 01586210\n",
      "31 . YES \t 08050800\n",
      "32 . YES \t 01410500\n",
      "33 . YES \t 14152000\n",
      "34 . YES \t 10287400\n",
      "35 . YES \t 01480675\n",
      "36 . YES \t 12413125\n",
      "37 . YES \t 02208450\n",
      "38 . YES \t 03110830\n",
      "39 . YES \t 01514000\n",
      "40 . YES \t 14056500\n",
      "41 . YES \t 09404343\n",
      "42 . YES \t 03075070\n",
      "43 . YES \t 04057510\n",
      "44 . YES \t 02300018\n",
      "45 . YES \t 01510500\n",
      "46 . YES \t 14052000\n",
      "47 . YES \t 08150800\n",
      "48 . YES \t 03294550\n",
      "49 . YES \t 06473000\n",
      "50 . YES \t 06191500\n",
      "51 . YES \t 01403540\n",
      "52 . YES \t 01614090\n",
      "53 . YES \t 06477500\n",
      "54 . YES \t 08395500\n",
      "55 . YES \t 11051499\n",
      "56 . YES \t 09340000\n",
      "57 . YES \t 06326500\n",
      "58 . YES \t 12353000\n",
      "59 . YES \t 02077200\n",
      "60 . YES \t 04292810\n",
      "61 . YES \t 09209400\n",
      "62 . YES \t 08291000\n",
      "63 . YES \t 09515500\n",
      "64 . YES \t 09073300\n",
      "65 . YES \t 01362497\n"
     ]
    }
   ],
   "source": [
    "modis_lst = ee.ImageCollection(\"MODIS/006/MYD11A2\") #aqua\n",
    "for i in range(len(shapefiles_list)):\n",
    "# for i in range(1):\n",
    "  shapefile = gpd.read_file(shapefiles_list[i])\n",
    "\n",
    "  features = []\n",
    "  for j in range(shapefile.shape[0]):\n",
    "    geom = shapefile.iloc[j:j+1,:]\n",
    "    jsonDict = eval(geom.to_json())\n",
    "    geojsonDict = jsonDict['features'][0]\n",
    "    features.append(ee.Feature(geojsonDict))\n",
    "\n",
    "  fc = ee.FeatureCollection(features)\n",
    "  bounds = fc.geometry().bounds()\n",
    "\n",
    "  # Day\n",
    "  lst_cel_day = modis_lst.map(preprocess_day).select(\"LST_Day_1km\")\n",
    "  lst_cel_region_day = lst_cel_day.map(region_temp).filter(ee.Filter.neq(\"LST_Day_1km\",None))\n",
    "\n",
    "  timeseries_day = lst_cel_region_day.aggregate_array(\"LST_Day_1km\").getInfo()\n",
    "  timestamp_day = lst_cel_region_day.aggregate_array(\"system:time_start\").getInfo() #miliseconds since epoch\n",
    "\n",
    "  dates_day = pd.to_datetime(np.array(timestamp_day)*1e6) #we have to scale the timestamp so it's in the proper units\n",
    "  day_series = pd.Series(timeseries_day,index=dates_day,name=\"Region Day LST\")\n",
    "\n",
    "  # Night\n",
    "  lst_cel_night = modis_lst.map(preprocess_night).select(\"LST_Night_1km\")\n",
    "  lst_cel_region_night = lst_cel_night.map(region_temp).filter(ee.Filter.neq(\"LST_Night_1km\",None))\n",
    "\n",
    "  timeseries_night = lst_cel_region_night.aggregate_array(\"LST_Night_1km\").getInfo()\n",
    "  timestamp_night = lst_cel_region_night.aggregate_array(\"system:time_start\").getInfo() #miliseconds since epoch\n",
    "\n",
    "  dates_night = pd.to_datetime(np.array(timestamp_night)*1e6) #we have to scale the timestamp so it's in the proper units\n",
    "  night_series = pd.Series(timeseries_night,index=dates_night,name=\"Region Night LST\")\n",
    "\n",
    "  #-----------------------\n",
    "  df = pd.concat([day_series, night_series], axis=1)\n",
    "  df['Region Daily Average LST'] = (df['Region Day LST'] + df['Region Night LST'])/2\n",
    "\n",
    "  # # df.plot(figsize=(15,11))\n",
    "  # file_PathName = '/content/drive/MyDrive/IDeA Lab/Temperature/Basin_Temp_ts/' + 'basin_' + shapefiles_list[i][-11:-4] + '.csv'\n",
    "  # print(shapefiles_list[i][-11:-4])\n",
    "  # df.to_csv(path_or_buf=file_PathName,index=True)\n",
    "\n",
    "  if len(df) > 0:\n",
    "    df = df['Region Daily Average LST']\n",
    "\n",
    "    file_PathName = 'Temp_TS/' + 'basin_' + shapefiles_list[i][-12:-4] + '.csv'\n",
    "    print(i, '. YES \\t', shapefiles_list[i][-12:-4])\n",
    "    df.to_csv(path_or_buf=file_PathName,index=True)\n",
    "    # print(\"exported!\")\n",
    "  else:\n",
    "    df = pd.DataFrame(data={})\n",
    "    file_PathName = 'Temp_TS/' + 'basin_' + shapefiles_list[i][-12:-4] + '.csv'\n",
    "    df.to_csv(path_or_buf=file_PathName,index=True)\n",
    "    print(i, '. NO \\t', shapefiles_list[i][-12:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yewOprxHKbG",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:14:03.947026Z",
     "start_time": "2024-01-20T03:14:03.940349Z"
    }
   },
   "source": [
    "#END"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lP3AJBbubEQ8",
    "ExecuteTime": {
     "end_time": "2024-01-20T03:14:07.871368Z",
     "start_time": "2024-01-20T03:14:07.859803Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2357971886.py, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[10], line 56\u001B[0;36m\u001B[0m\n\u001B[0;31m    print(i, '. NO \\t', shapefiles_list[i][-12:-4])[]\\\u001B[0m\n\u001B[0m                                                      ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "lst_cel_day = modis_lst.map(preprocess_day).select(\"LST_Day_1km\")\n",
    "lst_cel_region_day = lst_cel_day.map(region_temp).filter(ee.Filter.neq(\"LST_Day_1km\",None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZL45HNNbTn6"
   },
   "outputs": [],
   "source": [
    "lst_cel_night = modis_lst.map(preprocess_night).select(\"LST_Night_1km\")\n",
    "lst_cel_region_night = lst_cel_night.map(region_temp).filter(ee.Filter.neq(\"LST_Night_1km\",None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEcC0VcShRaP"
   },
   "outputs": [],
   "source": [
    "timeseries_day = lst_cel_region_day.aggregate_array(\"LST_Day_1km\").getInfo()\n",
    "timestamp_day = lst_cel_region_day.aggregate_array(\"system:time_start\").getInfo() #miliseconds since epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oE0gmxDDhVuW"
   },
   "outputs": [],
   "source": [
    "dates_day = pd.to_datetime(np.array(timestamp_day)*1e6) #we have to scale the timestamp so it's in the proper units\n",
    "day_series = pd.Series(timeseries_day,index=dates_day,name=\"Region Day LST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUaMbS9HhZn9"
   },
   "outputs": [],
   "source": [
    "timeseries_night = lst_cel_region_night.aggregate_array(\"LST_Night_1km\").getInfo()\n",
    "timestamp_night = lst_cel_region_night.aggregate_array(\"system:time_start\").getInfo() #miliseconds since epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYO6hOZHhdIk"
   },
   "outputs": [],
   "source": [
    "dates_night = pd.to_datetime(np.array(timestamp_night)*1e6) #we have to scale the timestamp so it's in the proper units\n",
    "night_series = pd.Series(timeseries_night,index=dates_night,name=\"Region Night LST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h22OTjGvhgVt"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([day_series, night_series], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "te14aTZLhjc7"
   },
   "outputs": [],
   "source": [
    "df['Region Daily Average LST'] = (df['Region Day LST'] + df['Region Night LST'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SB7HY3FMjKC6"
   },
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv ('/content/drive/MyDrive/IDeA Lab/Temperature/provo_temp_gauge_noaa.csv', names=['Date','TAVG (Degrees Fahrenheit)', 'TMAX (Degrees Fahrenheit)',\t'TMIN (Degrees Fahrenheit)',\t'PRCP (Inches)',\t'SNOW (Inches)',\t'SNWD (Inches)'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
